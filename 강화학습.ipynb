{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4aaf2bc",
   "metadata": {},
   "source": [
    "# OPENCV,mediapipe를 활용한 손가락 관절 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "mpHands=mp.solutions.hands\n",
    "\n",
    "hands=mpHands.Hands()\n",
    "print(hands)\n",
    "\n",
    "mpDraw=mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    #openCV는 RGB를 BGR로 저장함\n",
    "    imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results=hands.process(imgRGB)\n",
    "    print(results.multi_hand_landmarks)\n",
    "    #손가락을 인식했다면\n",
    "    if results.multi_hand_landmarks:\n",
    "        for i in results.multi_hand_landmarks:\n",
    "            mpDraw.draw_landmarks(img,i)\n",
    "    cv2.imshow('text',img)\n",
    "    #1밀리초마다 0xFF비트를 검사해서 q 눌렀으면 종료\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353b43d",
   "metadata": {},
   "source": [
    "# 랜드마크 간 선 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "mpHands=mp.solutions.hands\n",
    "hands=mpHands.Hands()\n",
    "mpDraw=mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    #이미지 반전하는 함수임, 1=좌우반전, -1=상하반전\n",
    "    img=cv2.flip(img,1)\n",
    "    imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results=hands.process(imgRGB)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for i in results.multi_hand_landmarks:\n",
    "            mpDraw.draw_landmarks(img,i,mpHands.HAND_CONNECTIONS)\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ddb6e8",
   "metadata": {},
   "source": [
    "# 8번 관절 타게팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "cap=cv2.VideoCapture(0)\n",
    "my_hands=mp.solutions.hands.Hands()\n",
    "mpDraw=mp.solutions.drawing_utils\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    image=cv2.resize(img,(1920,1080))\n",
    "    image=cv2.flip(image,1)\n",
    "    f_height,f_width,idx=image.shape\n",
    "    rgb_img=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    #손인식 결과\n",
    "    output=my_hands.process(rgb_img)\n",
    "    hands=output.multi_hand_landmarks\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            mpDraw.draw_landmarks(image,hand)\n",
    "            landmarks=hand.landmark\n",
    "            for id, landmark in enumerate(landmarks):\n",
    "                x=int(landmark.x*f_width)\n",
    "                y=int(landmark.y*f_height)\n",
    "                if id==8:\n",
    "                    cv2.circle(img=image,center=(x,y),radius=20,color=(0,255,0),thickness=10)\n",
    "\n",
    "    # cv2.imshow('img',image)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ee1cb",
   "metadata": {},
   "source": [
    "# 클래스 직접구현(잡다한 기능을 붙힐 수 있음. 가장 최신의 손은 초록 점으로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab2c7e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m flag,img=cap.read()\n\u001b[32m     40\u001b[39m img=cv2.flip(img,\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m img=\u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m lmList=detector.findPosition(img)\n\u001b[32m     44\u001b[39m cv2.imshow(\u001b[33m'\u001b[39m\u001b[33mimg\u001b[39m\u001b[33m'\u001b[39m,img)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mhandDetector.findHands\u001b[39m\u001b[34m(self, img, draw)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfindHands\u001b[39m(\u001b[38;5;28mself\u001b[39m,img,draw=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     17\u001b[39m     imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28mself\u001b[39m.results=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhands\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.results.multi_hand_landmarks:\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m handLms \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.results.multi_hand_landmarks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimknife\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[39m, in \u001b[36mHands.process\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np.ndarray) -> NamedTuple:\n\u001b[32m    133\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m \u001b[33;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimknife\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[39m, in \u001b[36mSolutionBase.process\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m    334\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m._graph.add_packet_to_input_stream(\n\u001b[32m    336\u001b[39m         stream=stream_name,\n\u001b[32m    337\u001b[39m         packet=\u001b[38;5;28mself\u001b[39m._make_packet(input_stream_type,\n\u001b[32m    338\u001b[39m                                  data).at(\u001b[38;5;28mself\u001b[39m._simulated_timestamp))\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cap=cv2.VideoCapture(0)\n",
    "#클래스 직접 만들어서 써보기\n",
    "class handDetector():\n",
    "    def __init__(self,mode=False,maxHands=2,modelComplexity=1,detectionCon=0.5,trackCon=0.5):\n",
    "        self.mode=mode\n",
    "        self.maxHands=maxHands\n",
    "        self.modelComplexity=modelComplexity\n",
    "        self.detectionCon=detectionCon\n",
    "        self.tranCon=trackCon\n",
    "        self.mpHands=mp.solutions.hands\n",
    "        self.hands=self.mpHands.Hands(self.mode,self.maxHands,self.modelComplexity,self.detectionCon,self.tranCon)\n",
    "        self.mpDraw=mp.solutions.drawing_utils\n",
    "\n",
    "    def findHands(self,img,draw=True):\n",
    "        imgRGB=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        self.results=self.hands.process(imgRGB)\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img,handLms,self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "    \n",
    "    def findPosition(self,img,handN=0,draw=True):\n",
    "        lmList=[]\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            mpHands=self.results.multi_hand_landmarks[handN]\n",
    "            for id, lm in enumerate(mpHands.landmark):\n",
    "                h,w,c=img.shape\n",
    "                cx,cy=int(lm.x*w),int(lm.y*h)\n",
    "                lmList.append([id,cx,cy])#21개 점 위치 저장하기\n",
    "                if draw:\n",
    "                    cv2.circle(img,(cx,cy),10,(155,255,0),cv2.FILLED)\n",
    "        return lmList\n",
    "detector=handDetector()\n",
    "\n",
    "while True:\n",
    "    flag,img=cap.read()\n",
    "    img=cv2.flip(img,1)\n",
    "\n",
    "    img=detector.findHands(img)\n",
    "    lmList=detector.findPosition(img)\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
